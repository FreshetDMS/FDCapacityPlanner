#!/usr/bin/env python

from vsvbp.container import *
from vsvbp.solver import *


class Partition(ConstrainedItem):
    def __init__(self, requirements, topic, pid, rid):
        super(Partition, self).__init__(requirements)
        self.topic = topic
        self.pid = pid
        self.rid = rid

    def __repr__(self):
        return str([self.requirements, self.topic, self.pid, self.rid])

    def is_constraint_satisfied(self, bin):
        for item in bin.items:
            if item.pid == self.pid:
                return False

        return True


ec2_instance_types = {
    "m4.large": [8 * 1024, 450 / 8, 125, 125],
    "m4.xlarge": [16 * 1024, 750 / 8, 125, 125],
    "m4.2xlarge": [32 * 1024, 1000 / 8, 125, 125],
    "m4.4xlarge": [64 * 1024, 2000 / 8, 125, 125],
    "m4.10xlarge": [160 * 1024, 4000 / 8, 1250, 1250],
    "m4.16xlarge": [256 * 1024, 10000 / 8, 2500, 2500]
}

N = 3
MILLION = 1000000
HUNDRED_THOUSAND = 100000
INDEX_SIZE = 10

TOPIC = "topic"
DATARATE = "datarate"
MESSAGE_SIZE = "messsage-size"
CONSUMERS = "consumers"
REPLAYS = "replays"
REPLAY_RATE = "replay-rate"
PARTITIONS = "partitions"
REPLICATION_FACTOR = "replication-factor"
MAX_LAG = "max-lag"

topics = []

for i in range(N):
    data_rate = MILLION + HUNDRED_THOUSAND * random.randint(5, 30)
    max_lag = random.randint(5, 20) * data_rate
    topics.append({
        TOPIC: "t-%d" % i,
        DATARATE: data_rate,
        MESSAGE_SIZE: 100 + 10 * random.randint(2, 10),
        CONSUMERS: random.randint(1, 6),
        REPLAYS: random.randint(1, 4),
        REPLAY_RATE: random.randint(1, 3) * data_rate,
        PARTITIONS: random.randint(50, 100),
        REPLICATION_FACTOR: 3,
        MAX_LAG: max_lag
    })

items = []

for t in topics:
    topic = t[TOPIC]
    partitions = t[PARTITIONS]
    message_size = t[MESSAGE_SIZE]
    per_part_datarate = ((t[DATARATE] * message_size) / MILLION) / partitions
    consumers = t[CONSUMERS]
    replays = t[REPLAYS]
    replication_factor = t[REPLICATION_FACTOR]
    replay_rate = ((t[REPLAY_RATE] * message_size) / MILLION) / partitions
    max_lag = t[MAX_LAG] / partitions
    for p in range(partitions):
        items.append(Partition(
            [INDEX_SIZE + ((max_lag * message_size) / MILLION), per_part_datarate + replays * replay_rate,
             per_part_datarate, (consumers + replication_factor - 1) * per_part_datarate + replays * replay_rate],
            topic, p, 0))
        # Replicas also need to support replays and consumers incase leaders goes down
        for j in range(replication_factor - 1):
            items.append(Partition(
                [INDEX_SIZE + ((max_lag * message_size) / MILLION), per_part_datarate + replays * replay_rate,
                 per_part_datarate, (consumers + replication_factor - 1) * per_part_datarate + replays * replay_rate],
                topic, p, j + 1))

max_network_out = max(items, key=lambda item: item.requirements[3]).requirements[3]
max_ebs = max(items, key=lambda item: item.requirements[1]).requirements[1]
max_mem = max(items, key=lambda item: item.requirements[0]).requirements[0]

print 'items', len(items)
print 'max network out', max_network_out
print 'max ebs bandwidth', max_ebs
print 'max mem', max_mem

least_suitable_instance_type = None
for key, value in ec2_instance_types.iteritems():
    if value[3] > max_network_out * 2 and value[1] > max_ebs * 2:
        least_suitable_instance_type = key
        break

print 'selected instance type:', least_suitable_instance_type

assignment = optimize(items, Bin(ec2_instance_types[least_suitable_instance_type]))
print 'bin count:', len(assignment.bins)
print assignment
